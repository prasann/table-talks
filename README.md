# ğŸ—£ï¸ TableTalk

A conversational EDA assistant that enables natural language exploration of data schemas using a local Small Language Model.

Ask questions like "Show me the schema of orders.csv" or "Which files have user_id?" instead of manually inspecting CSV and Parquet files.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Ollama with Phi-3 model (`ollama serve` + `ollama pull phi3:mini`)

### Installation
```bash
python -m venv venv
source venv/bin/activate  # Always activate first!
pip install -r requirements.txt
python src/main.py
```

### First Steps
```bash
TableTalk> /scan data/sample          # Scan sample data
TableTalk> What files do we have?     # See available files  
TableTalk> Show me the schema of orders.csv  # Explore structure
TableTalk> /exit                      # Done
```

## ï¿½ Documentation

- **[Usage Guidelines](USAGE.md)** - Commands, examples, and best practices
- **[Troubleshooting](TROUBLESHOOTING.md)** - Common issues and solutions  
- **[Design Document](vibe-collab/design_document.md)** - Architecture and technical details

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ metadata/           # Schema extraction & DuckDB storage
â”œâ”€â”€ tools/              # LangChain tool functions  
â”œâ”€â”€ agent/              # LLM agent & context management
â”œâ”€â”€ cli/                # Interactive interface
â””â”€â”€ main.py             # Entry point
```

Ready to explore your data schemas! ğŸš€

## ğŸ“‹ Available Commands

### CLI Commands
- `/scan <directory>` - Scan files in directory for schema information
- `/help` - Show available commands and example queries
- `/status` - Display system status and database statistics
- `/clear` - Clear conversation memory
- `/exit` or `/quit` - Exit TableTalk

### Natural Language Queries
**File Information:**
- "What files do we have?"
- "List all scanned files"
- "Show me a summary of the database"

**Schema Exploration:**
- "Show me the schema of orders.csv"
- "Describe the structure of customers.csv"
- "What columns are in reviews.csv?"

**Cross-File Analysis:**
- "Which files have a user_id column?"
- "Find columns that appear in multiple files"
- "What columns are common across all files?"

**Data Quality:**
- "Find data type inconsistencies"
- "Detect type mismatches across files"
- "Are there any schema conflicts?"

### Example Workflow
```bash
TableTalk> /scan data/sample                    # Scan sample data
TableTalk> What files do we have?               # See available files
TableTalk> Show me the schema of orders.csv     # Explore specific file
TableTalk> Find common columns across files     # Cross-file analysis
TableTalk> Detect type mismatches              # Quality check
TableTalk> /status                             # System overview
TableTalk> /exit                               # Done
```

## ğŸ“Š Current Status

âœ… **Completed (MVP Core)**
- âœ… Project structure and configuration
- âœ… DuckDB metadata storage
- âœ… CSV/Parquet schema extraction
- âœ… LangChain tool integration
- âœ… Ollama + Phi-3 agent setup
- âœ… Interactive CLI interface
- âœ… Sample data files
- âœ… Basic test framework
- âœ… Setup automation

ï¿½ **Ready for Testing**
The MVP is complete and ready for testing! You can:
1. Scan directories for CSV/Parquet files
2. Ask natural language questions about schemas
3. Find type mismatches and common columns
4. Get file summaries and database statistics

## ï¿½ğŸ“ Project Structure

```
table-talk/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ metadata/       # Schema extraction and DuckDB storage
â”‚   â”œâ”€â”€ tools/          # LangChain tool functions
â”‚   â”œâ”€â”€ agent/          # LLM agent and context management
â”‚   â”œâ”€â”€ cli/            # Command-line interface
â”‚   â””â”€â”€ main.py         # Entry point
â”œâ”€â”€ tests/              # Unit tests
â”œâ”€â”€ data/sample/        # Sample CSV files for testing
â”œâ”€â”€ config/             # Configuration files
â”œâ”€â”€ setup.sh           # Automated setup script
â””â”€â”€ requirements.txt    # Python dependencies
```

## ğŸ§ª Testing with Sample Data

TableTalk comes with sample CSV files to test all features immediately:

### Quick Test (2 minutes)
```bash
# 1. Start TableTalk
python src/main.py

# 2. Scan the sample data
TableTalk> /scan data/sample

# Expected output:
# ğŸ” Scanning directory: data/sample
# âœ“ customers.csv: 6 columns
# âœ“ orders.csv: 6 columns  
# âœ“ reviews.csv: 6 columns
# âœ… Scan complete: 3 files, 18 columns processed

# 3. Test natural language queries
TableTalk> What files do we have?
TableTalk> Show me the schema of orders.csv
TableTalk> Which files have customer_id?
TableTalk> Find common columns across files
TableTalk> Detect type mismatches

# 4. Exit
TableTalk> /exit
```

### Sample Data Overview
The `data/sample/` directory contains:
- **orders.csv**: E-commerce orders (10 rows, 6 columns)
  - `order_id`, `customer_id`, `product_name`, `quantity`, `price`, `order_date`
- **customers.csv**: Customer information (6 rows, 6 columns)
  - `customer_id`, `first_name`, `last_name`, `email`, `signup_date`, `is_active`
- **reviews.csv**: Product reviews (6 rows, 6 columns)
  - `review_id`, `user_id`, `product_name`, `rating`, `review_text`, `created_date`

### Expected Test Results
1. **Common columns**: `customer_id` (orders.csv + customers.csv), `product_name` (orders.csv + reviews.csv)
2. **Type consistency**: All data types should be consistent across files
3. **Schema details**: Each file's column types, null counts, and unique values

### Testing Your Own Data
```bash
# Scan your own CSV/Parquet files
TableTalk> /scan /path/to/your/data/directory

# Ask questions about your data
TableTalk> Show me the schema of your_file.csv
TableTalk> Find type mismatches
TableTalk> What columns appear in multiple files?
```

## ğŸ”§ Troubleshooting

### Common Issues & Solutions

**1. "Cannot connect to Ollama" Error**
```bash
# Start Ollama service
ollama serve

# In another terminal, test connection
curl http://localhost:11434/api/tags

# Pull the model if needed
ollama pull phi3:mini
```

**2. "Import Error" or Module Not Found**
```bash
# Make sure you're in the virtual environment
source venv/bin/activate

# Reinstall dependencies
pip install -r requirements.txt
```

**3. "No files found" when scanning**
```bash
# Check file formats (only CSV and Parquet supported)
ls -la your/data/directory/

# Use absolute path
TableTalk> /scan /absolute/path/to/data
```

**4. Database Errors**
```bash
# Delete and recreate database
rm -rf database/
mkdir -p database

# Make sure virtual environment is activated
source venv/bin/activate  # Critical step!

# Run TableTalk (will recreate clean database)
python src/main.py
```

**5. LLM Agent Not Available**
- Ensure Ollama is running: `ollama serve`
- Check model is installed: `ollama list`
- You can still use `/scan` commands without the LLM

**6. "Module not found" errors**
```bash
# Always activate virtual environment first
source venv/bin/activate

# Verify activation (should show (venv) in prompt)
which python

# Then run TableTalk
python src/main.py
```

### Getting Help
- Use `/help` in TableTalk for available commands
- Check logs in `logs/tabletalk.log` for detailed error information
- Use `/status` to check system status

## ğŸ”§ Next Steps

**Phase 2 Enhancements:**
- [ ] Docker containerization
- [ ] Enhanced data profiling
- [ ] Data quality scoring
- [ ] Cross-file relationship detection
- [ ] Web interface (Streamlit)

## ğŸ› ï¸ Development

See `TableTalk_MVP_Plan.md` for detailed implementation plan and development guidelines.

## ğŸ“„ License

MIT License - see LICENSE file for details.
